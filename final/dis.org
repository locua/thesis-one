#+title: Describing systems for the exploration of tangible and spatial computer interaction  
#+title: \\ 
#+author: Louis James
#+options: h:2 num:t toc:nil \n:nil
#+subtitle: Final year project for Creative Computing Bsc \\
#+subtitle: Goldsmiths University of London
#+latex_class: book
#+latex_header_extra: \input{config.tex}
#+LATEX_HEADER: \setlength{\parindent}{0pt}
#+LATEX_HEADER: \usepackage[margin=1in]{geometry}
#+LATEX_HEADER: \usepackage{emptypage}

* other title ideas :noexport:
# #+title: Spatial memory, embodied thinking, computer vision projection application \\
# #+title: or \\
# #+title: Exploring cognition and interaction in a spatial and physicalised computer environment. \\
# #+title: or \\
* Acknowledgements :ignore:
\renewcommand{\abstractname}{Acknowledgements}
\begin{abstract}
 Thanks to my family, Florent, Chudleigh dwellers, Jamie ...
\end{abstract}
\newpage

* Abstract :ignore:
\renewcommand{\abstractname}{Abstract}
#+LaTeX: \begin{abstract}
Presented here is a specification for experimental approaches to computer
interaction based on spatial and tangible methods. The report describes an
prototypical implementation of a base system for computer interaction using
physical objects on a surface. A theoretical API for such a system and similar
systems is proposed. This utilises computer vision techniques to analyse a
surface to track objects and the projection of graphics onto the space creating
a feedback system for interaction. An attempt to gather together literature and
examples of such existing systems is made. The fundamental principle of the
interaction system here described is summarised in the sentence below:

#+begin_quote
Physical objects on an /action surface/ have interactive properties, each object
is both a sensor and actuator.
#+end_quote



# ???An ethnomethodological framework for evaluation and further development
# is proposed???


#+LaTeX: \end{abstract}
* Toc :ignore:
\tableofcontents
#+latex: \listoffigures
* Introduction

** Project aims

- open source project for tangible interaction
- Prototypical
- ethnomethodological frameworks for evaluation

* Background label:background

The motivation for this project stems in part from a feeling of frustration in
 how working on computers can often be a constricted affair and a pondering over
 how we might expand the /keyboard-mouse-monitor/ model to improve the utility
 of computers regarding our physical health, wellbeing and perceptive abilities.
 How might a spatial, haptic and tangible environment for interaction create an
 improved space for working and thinking with computers as well with our
 physical health? How might such an environment fundamentally augment our
 cognitive capabilities; memory and learning as well as creativity itself?
 
** Definitions
*** HCI - Human Computer Interaction
*** KMM - keyboard-mouse-monitor model 
*** Exocortex - 

** /Exocortices/ and augmented cognition

I started off looking at /Exocortices/ and other personal archiving systems.
Systems that allow the user to externalise thought and memory. This could be via
simply storing and organising work and ideas efficiently and methodically or
unifying many tasks or different workflows into a singular interface. 

Org mode is a good example of such a system. Org mode is a "computing
environment for authoring mixed natural and computer language documents"
cite:Schulte:Davison:Dye:Dominik:2011:JSSOBK:v46i03. It is designed for taking
notes, producing documents and organising and runs inside of the text editor,
Emacs. It has the ability to export to different formats such as HTML, LaTeX and
supports "outlining, note-taking, hyperlinks, spreadsheets, TODO lists, project
planning, GTD" as well as literate programming, all in plain-text
cite:Schulte:Davison:Dye:Dominik:2011:JSSOBK:v46i03 (it is incidentally what
this document is produced with). \\

Another point of reference when I was looking at externalised 'artificial
information-processing systems' was Devine Lu Linvega's Exocortex [[https://wiki.xxiivv.com/site/nataniev.html][XXIIV --
nataniev]]. /XXIIV/ is a personal archive and log with documentation of Linvega's
personal tools and artworks. The site has gone through some changes since I
first came across it. Originally a static, javascript and lisp based website
with diaries, blog type posts and categorised personal logs. It is now somewhat
stripped back in style and has been rewritten in [[https://en.wikipedia.org/wiki/C99][C (C99)]]. The work contains a
selection of esoteric programming tools including a synthetic language, games,
software all logged using their own /Arvelie calendar/ cite:DevineNataniev. \\

Both these two systems have their own specific use-cases, /Org-mode/; in
academia and science and /XXIIV/; an experimental personal archive. They both
utilise the contemporary and prevailing /keyboard-mouse-monitor/ paradigm
of computer interaction but push the boundaries of cognition in this medium,
particularly regarding memory and productivity. These two projects were a birth
point in thinking about how software systems can be augment thought and improve
learning ability and computer productivity. \\

# ** Nielsen: augmenting ltm and using ai to augment human-i ??????

Information visualization is a tool for the augmenting and
externalising cognition that most take for granted. cite:WareColin2013Ivpf

cite:NielsenMich2018altm,carter2017using  

** A virtual exploration of a 'dynamic land'

Another original and critical point of reference was /Dynamicland/, a research
project in Oakland, USA. The aim of the project is to implement a new more
powerful and accessible model of computing.

#+begin_quote

In Oakland, we built the first full-scale realization of the vision, inviting
thousands of people into our space to collaborate. Together, these artists,
scientists, teachers, students, programmers, and non-programmers created
hundreds of projects that would have been impossible anywhere else.
-- Dynamicland.org 

#+end_quote


/Dynamicland/ is a communal computer where the building is the computer (ENIAC).
Programs are embodied in the room on pieces of colour-coded paper. The programs
are recognised via the codes and their code, stored in a database is then run,
it can also /read/ code using OCR but generally the code is there [[https://thenewstack.io/dynamicland-rethinks-computer-interfaces/][symbolically]].
Projectors on the ceiling transform the paper and workbenches into whatever the
programmer decides. This relatively simple model makes for an exciting new
ecosystem for collaborative computing and expressive programming. Victor
highlights his ideas for the progression of computing and interaction in a
series of talks (available online) and on his [[http://worrydream.com][website]]. In his talk "Seeing
Spaces" he talks of a new kind of maker-space which allow makers to see across
time and possibilities. /Dynamicland/ seeks to offer a computational medium
which allows for full use of the human senses and a more [[https://vimeo.com/115154289][humane representation
of thought]] cite:VictorKayDynamicLand. \\

#+caption: RealtalkOS, the operating system of /Dynamicland/
#+ATTR_LATEX: :width 12cm
[[file:assets/realtalk-os.jpg]]  


/DL/ was a major inspiration for the main technical model for this project, an
/augmented/ workspace either on the floor or a table which is projected onto. A
camera/s pointing down onto the projection space is the sensor for detecting
interaction, with the projector as the actuator. This base model can be seen in
Figures ref:pp-schema and ref:systemSchema.


*** Dynamiclands opensource model :noexport:

** Paper programs 

Looking to find some of the code for /Dynamicland/ and a more detailed
specification of *DL* I stumbled across /Paper Programs/ (PP) ( /Dynamicland/ has
an 'open-source model', but it is only open if you can visit it physically as
the source code is physically in the space). /Paper Programs/ (PP) is a browser-based
partial clone of /Dynamicland/. PP takes one element of dynamicland, i.e. the
representation of computer programs in a spatial environment, on pieces of
paper. Programs are written in Javascript and stored in a Postgresql database.
This idea of 'physicalizing' some method or element of the computer and allowing
the direct haptic manipulation of it has further inspired this project. \\

#+ATTR_LATEX: :width 12cm  :float
#+caption: /Paperprograms/ in action label:pp-users
[[file:assets/pp_action2.png]]

PP aims, like Dynamicland, to create a collaborative programming environment
where each anyone in the space can write Javascript programs and interact with
others. As in DL each program has a unique code and a colour encoding. It
follows the same basic hardware model. That being a projector and camera on the
ceiling and the paper "programs" (See Fig. ref:pp-schema.). This new vision of
collaborative computing and multi-modal interaction is one of the initial
motivations for creating a...


#+caption: The initial physical schema: /Paperprograms/ label:pp-schema
#+ATTR_LATEX: :width 10cm :float
[[file:assets/pp-diag.png]]

** Implementation and abstraction label:implement_and_abstraction

In the SAGE Handbook of Digital Technology Research's chapter on Haptic
interfaces design parameters are listed:

- Cutaneous Perception
- Frequency
- Duration
- Rhythm
- Location
- Intensity
- Texture
- Kinesthetic Perception
- ...

These parameters present considerations for the design of such interfaces but
also a formalisation of haptic interaction in the abstract
cite:HigginsSteve2015TSho. It takes the possible of elements 'hapticity' and
lays them out. This motivated a second outcome to the implementation itself, to
construct a /formal/ specification for spatial and tangible interaction so as to
describe the elements conceptually. This could then be used for further
development of similar systems and allow for multi-disciplinary scientific
experimentation. The benefits of having such a blueprint would be to present
spatiality and tangibility (in relation to HCI) formally so as to allow for
identification of elements for use.


*** notes 
Moving from implementation to abstraction

Ethnomethodology

Embodied Cognition

Haptic interfaces


- Touch is bi-directional, percieve and actuate via touch
  - Touch is an input and output tool in HCI
- Also can be active and passive. Exploration of object vs /passive/ eg
  vibrotactile actuators in a mobile phone vibrating when phone rings.
- Standardised keyboard shortcuts
- In cog sci looking to explore the phenomena on a cognitive level while in HCI
  approach we are looking to formalise the computational interaction system /
  schema


** Tangible bits - Hiroshi Ishii  and  Brygg Ullmer
cite:IshiiH2002Tbdt

- Ubiquitous computing
- IOT

*** MIT Prof - tangible media group
http://tangible.media.mit.edu/projects/

** Multi-modal installation project 

An experimental [[https://locua.github.io/posts/install-y1.html][project]] I produced in 2017 has also informed the direction of
this project. This work was a multi-modal paint program where different hand
movements and facial expressions controlled different parameters of a paint
program. This included colour, size and position of the stroke. Additionally the
different modes of input were also controlling parameters on a looping
synthesizer. The installation was multi-modal in input and output. It was an
artwork in outlook but formed an initial experiment in designing HCI.

#+caption: Multi-modal painting
#+ATTR_LATEX: :width 11cm
[[file:assets/multi-modal-proj1.png]]

#+caption: Modal schematic
#+ATTR_LATEX: :width 15cm
[[file:assets/multi-modal-proj-diag.png]]




** mental and physical health implications of contemporary computing ? Are they really quite minor? :noexport:
** Computational creativity? :noexport:

*** Open source

*** alex mclean thesis


** Main refs :noexport:
- Interaction design beyond HCI cite:SharpHelen2019IDBH
- Sage handbook of digital technology research cite:HigginsSteve2015TSho
  - Embodied cognition
  - Haptic interfaces
    - Augmented planning workbench cite:IshiiH2002Aupw 
  - Ethnomethodology
    - As an evaluative framework cite:HigginsSteve2015TSho
- Dynamicland cite:VictorKayDynamicLand
- The design of everyday things cite:TennerEdward2015TDoE
- Tidal cycles, Alex mcleans thesis ???
- Why increases in adolescent depression may be linked to the technological environment cite:TwengeJeanM2020Wiia
- Augmenting long term memory cite:NielsenMich2018altm 
  
* Specification and context

To sum up the fundamental principle of the style of interaction that this
document aims to describe is summarised in the sentence below.

#+begin_quote
Physical objects on an /action surface/ have interactive properties, each object
is both a sensor and actuator.
#+end_quote

I provide this foundation so as to differentiate it between commonly used
contemporary systems. It highlights that a 'live' surface will act as a space
where objects are augmented with additional properties i.e. input and output to
a computer system. \\

As in the original specification the aim was to create a system for spatial
interaction. Initially I imagined it to work on a table top surface (in the end
it was developed on a floor mat due to considerations in my development
environment; see Chapter ref:projectindepth). The other principle component was
to that interaction would be based on the placement and movement of objects
around the work-surface. The position and movements of theses objects would be
picked up by a camera and actuated by a projector; both situated above the
surface looking down onto it. It could also be setup in a horizontal direction,
with, for example, magnetised components keeping the objects to a board.
Alongside this a computer keyboard may be used for additional input such as
inputting text or selecting something. \\

The original plan was to use /Paperprograms/ and build on top of this. With the
paperprograms system, I planned to build, a program to explore the psychology of
interaction with such a system. This could take the form of a game-like
psychology experiment. However for risk of attempting a psychology thesis within
a computing major this scope was switched to creating and exploring the
implementation and formalisation of the interaction system itself.

Due to technical issues with PP and the motivation to explore an alternative
interaction model, I decided to implement the system using openFrameworks, a C++
toolkit for experimental application development. I chose this framework as it
has straightforward 'out of the box' graphics capabilities as well as numerous
Add-ons which include /OpenCV/ cite:opencv_library wrappers and GUI libraries as
well as an active community of users. This combination in one framework seemed
suitable for quick experimentation and prototyping for the project. The physical
setup would include a Projector and HD webcam and computer for running the
application. See Fig. ref:systemSchema for the software and hardware schematic
for this technical conception. \\

#+caption: System schema label:systemSchema  
#+ATTR_LATEX: :width 10cm
[[file:assets/project-schema-final.png]]

Another design consideration I had in mind was accessibility. From my research
into similar projects an aim was to create a similar system that could be open
source and easily setup so that others could build on top of the system. This
was another reason for using [[https://openframeworks.cc/download/][openFrameworks]] which is cross platform (Windows,
OSx, IOS and Linux). This would mean with minor or no modification of the code,
it could be run on any all the major desktop platforms. The hardware
requirements are also the kind which are either cheaply (relatively) sourced or
commonly available in educational institutions; one of the target areas that
further development was envisioned. \\

Due to the limited scope of this project in both time and academic context a
secondary theoretical component is conceived. This is in the form of a
theoretical specification and API for this project and similar systems. As
discussed previously (ref:implement_and_abstraction) a set of parameters and
variables can form a useful part of a conceptual illustration and formalisation.

#+caption: Abstract system schema label:systemSchema  
#+ATTR_LATEX: :width 11cm
[[file:assets/abstract-system-schema.png]]



* Project in depth label:projectindepth

** Implementation details

** Final Build

** Raspberry pi testing

** Abstract Spec

** API

* Creative process

As mentioned /Paperprogams/ was a starting point for playing around with but I found that I
couldn't set it up and have it stable enough to develop on. It also suffers from
being quite slow, due to the Computer Vision and graphics being done in the
browser (it uses a version of OpenCv compiled to [[https://webassembly.org/][WebAssembly]])
cite:JpPaperPrograms. While WebAssembly has the scope for doing high-performance
computation in the browser but I found there was still a significant lag from
detecting papers to projecting back down on to them. Another branch which had
implemented blob detection on the GPU I also found to be slow and unstable ([[https://github.com/janpaul123/paperprograms/pull/28][Link
to pull request]]), this may have been due to my lighting and camera setup.

** Goverened by 
*** ...technical implementability
*** ...research and experience

* Debugging and problem solving
* Evaluation and Conclusions
* Research notes :noexport:
** SAGE GUIDEBOOK for digital technology research
*** Theories of embodiment in HCI
*** Haptic interfaces
"the widgets cannot provide the haptic response that physical objects do when
touched or clicked. By adding haptic feedback to user interfaces, we can
recreate the physical sensation of pressing a button, holding a ball or even
create completely new touch sensations."

*** ethno methodology
- Propose and trial ethnomethodological framework for project evaluation
* Links :noexport:
- http://web.mit.edu/ebj/www/JPER.pdf - similar project - urban planning workbench
- Sage digital tech research handbook
  - embodied interaction
  - haptic interfaces
  - ethnomethodology 

* Bibliography :ignore:

bibliographystyle:ieeetr 
bibliography:references.bib

* Appendix :ignore:

